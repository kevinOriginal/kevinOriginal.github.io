---
layout: post
title: Introducing Lanyon
---
## 이것은 테스트 포스트 입니다.
한 번 해보는 중 !

> # 어떤식으로 할 때 가장 이쁠 것인가
 Lorem Ipsum
> ## 어떤식으로 할 때 가장 이쁠 것인가

> ### 어떤식으로 할 때 가장 이쁠 것인가



그들에게 알맞는 곡선을 계산하고 찾는 행위가 결국 Curve Fitting이다. 이를 조금 더 수학적으로 나타내보자. 우리에게 training set $\mathbf{x} \equiv [x_1, \cdots, x_N]^T$ 과 각 $x$값에 대응하는 $\mathbf{t} \equiv [t_1, \cdots, t_N]$ 이 주어져 있다고 해보자. 이를 좌표평면에 대응하면 다음과 같이 나타낼 수도 있다.
$$
(x_1,t_1), (x_2,t_2),\cdots,(x_N, t_N)
$$

결국 우리의 목표는 training set으로 학습시킨 알고리듬(함수)에 input 값 $\hat{x}$ 에 대한 결과 $\hat{t}$를 예측해내는 것이 목표이다. 여기서 학습시킨 함수는 당연히 곡선들이 될 것이다. curve fitting은 굉장히 다양한 형태의 그래프로 이루어질 수 있지만, 우리는 일단 다항함수로 이루어진 curve fitting을 다룰 것이다. 즉 주어진 데이터를 다음과 같은 polynomial function(다항 함수)으로 나타낼 것이다.
$$
y(x, \mathbf{w} ) = w_0 + w_1x+ w_2x^2 + \cdots + w_Mx^M=\sum_{j=0}^M{w_jx^j}
$$
여기서 $\mathbf{w}$는 $x$의 coeffeicient $w_0,\ w_1,\ \cdots \ w_M$를 벡터화 한 것이다. 결국 우리가 찾고 싶은 것이 $\mathbf{w}$의 값이다. 이 계수들을 **파라미터(parameter)** 라고도 한다. 만약 $\mathbf{w}$의 값을 알아낸다면, 새로운 $\hat{x}$ 값을 함수 $y(x, \mathbf{w} )$ 에 대입하여 결과값 $y(x_1, \mathbf{w} ) = \hat{t}$를 알아낼 수 있을 것이다.

여기서 잠시 생각해보자. 수학에서 **함수** 는 항상 변수와 상수를 구분하는 것이 중요하다. 따라서 우리도  *어떠한 관점* 에서 함수 $y(x, \mathbf{w} )$를 바라볼 것인지를 생각해보아야 한다. $x$의 관점에서 $y(x, \mathbf{w} )$는 $x$에 대해서 비선형적인 함수이지만 coeffeicient $\mathbf{w}$의 관점에서 바라본다면 이는 선형적인 함수가 된다. 이가 중요한 이유는 만약 $\mathbf{w}$ 에 대하여 함수를 바라본다면, 즉 이가 선형함수가 된다면 *linear model* 이 되여, 앞으로 우리가 연산을 할 때, 아주 핵심적인 역할을 할 것이기 때문이다.

그럼 실제로 각 coeffeicient인 $\mathbf{w}$들의 값은 어떻게 찾아낼 수 있을까? 일단, training data의 점들을 저 다항함수를 맞춰서 낑겨넣으면 된다. 여기서 가장 핵심은 오차값을 줄이는 것이다. 이 오차를 *error function* 이라고 부르며 이 역시 함수임을 인지하자. 여하튼 *error function* 은 모든 $x$에 대하여 예측값에서 실제값의 차의 제곱을 다 더한것에 해당한다. 수식으로 정리하면 다음과 같다.
$$
E(\mathbf{w)}= {1\over2}\sum_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2
$$
여기서 임의의 $\mathbf{w}$ 에 대한 $y(x_n, \mathbf{w} )$ 은 예측값이고, $t_n$은 실제 training data의 값이다.
잠깐만... error..? 에러는 적을수록 좋은것이 아닌가?
그렇다. 우리는 이 에러 함수를 **최소화** 시키는 작업을 통해 더욱 모델에 알맞는 함수를 구현할 수 있게 된다. 따라서 우리는 $E(\mathbf{w)}$ 의 값을 가장 최소로 만드는 $\mathbf{w}$의 값을 찾는것이 목표이며 이는 미분을 통해 할 수 있게 된다. $E(\mathbf{w)}$는 $\mathbf{w}$ 에 대해 선형적인 함수 이므로 이의 도함수 역시 유일한 해를 가지게 된다. 따라서 그 유일한 해를 앞으로 $\mathbf{w}_m$라 칭할 것이다.
하지만 아직 문제 하나가 남아 있다. $y(x_n, \mathbf{w})$ 를 다시 한 번 살펴보자.
$$
y(x, \mathbf{w} ) = w_0 + w_1x+ w_2x^2 + \cdots + w_Mx^M=\sum_{j=0}^M{w_jx^j}
$$
아직 $M$의 값(최고차항)이 결정되지 않았다. 곡선을 몇차함수로 나타낼 것인지가 문제인 것이다.
